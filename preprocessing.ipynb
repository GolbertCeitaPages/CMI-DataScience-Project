{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af7aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# These are the column names:\n",
    "\"\"\"\n",
    "Unique: \n",
    "tourney_id,tourney_name,surface,draw_size,tourney_level,tourney_date,match_num,score,best_of,round,minutes\n",
    "\n",
    "prefixed with winner/loser:\n",
    "winner_id,winner_seed,winner_entry,winner_name,winner_hand,winner_ht,winner_ioc,winner_age,winner_rank,winner_rank_points\n",
    "\n",
    "prefixed with w/l:\n",
    "w_ace,w_df,w_svpt,w_1stIn,w_1stWon,w_2ndWon,w_SvGms,w_bpSaved,w_bpFaced\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4a451",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path.cwd()\n",
    "\n",
    "def create_match_table(year):\n",
    "    dataframes = []\n",
    "    \n",
    "    sources = [\n",
    "        (\"matches\", \"atp_matches\", f\"atp_matches_{year}.csv\"),\n",
    "        (\"challengers\", \"atp_qual_chall\", f\"atp_matches_qual_chall_{year}.csv\"),\n",
    "        (\"futures\", \"atp_futures\", f\"atp_matches_futures_{year}.csv\")\n",
    "    ]\n",
    "    \n",
    "    for tourney_type, folder, filename in sources:\n",
    "        path = BASE_DIR / \"atp_sources\" / folder / filename\n",
    "        try:\n",
    "            df = pd.read_csv(path)\n",
    "            df[\"tourney_type\"] = tourney_type\n",
    "            dataframes.append(df)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: {filename} not found, skipping.\")\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Warning: {filename} is empty, skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}, skipping.\")\n",
    "\n",
    "    if not dataframes:\n",
    "        raise ValueError(f\"No datasets found for year {year}.\")\n",
    "    \n",
    "\n",
    "    # Concatenate available tables\n",
    "    big_match_table_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Post processing to round age columns safely\n",
    "    big_match_table_df[\"winner_age\"] = round(big_match_table_df[\"winner_age\"],0)\n",
    "    big_match_table_df[\"loser_age\"] = round(big_match_table_df[\"loser_age\"],0)\n",
    "\n",
    "    big_match_table_df[\"score\"] = big_match_table_df[\"score\"].replace(\"6-36-3\",\"6-3\")\n",
    "\n",
    "    # rename round to avoid calling round method/function\n",
    "    big_match_table_df = big_match_table_df.rename(columns={\"round\":\"tourney_round\"})\n",
    "\n",
    "    # create all columns as nan columns and then cast as object type to prevent warnings\n",
    "    all_rounds_cols = [\"round_1\", \"round_2\", \"round_3\", \"round_4\", \"round_5\"]\n",
    "    big_match_table_df[all_rounds_cols] = np.nan\n",
    "    big_match_table_df[all_rounds_cols] = big_match_table_df[all_rounds_cols].astype(\"object\")\n",
    "\n",
    "    MAX_SETS = 5\n",
    "    \n",
    "    # split scores into round columns\n",
    "    split_rounds = big_match_table_df['score'].fillna(\"\").str.split(\" \", n=MAX_SETS-1, expand=True)\n",
    "    \n",
    "    for i, col in enumerate(all_rounds_cols):\n",
    "        big_match_table_df[col] = split_rounds[i].replace(\"\", pd.NA)  # convert empty strings to NA\n",
    "\n",
    "    REPLACED_ROUND_VALUES = ['RET', 'RE', 'W/O', 'DEF', 'Def.', \"Ret'd\", 'default', \n",
    "                         'walkover','played','and','abandoned','unfinished','&nbsp;',\n",
    "                         '>','Mar-00','May-00','UNK','Walkover','ABD','Played','Default','and abandoned']\n",
    "    \n",
    "    for col in all_rounds_cols:\n",
    "        big_match_table_df[col] = big_match_table_df[col].replace(REPLACED_ROUND_VALUES, pd.NA)\n",
    "        # remove the trailing RET values\n",
    "        big_match_table_df[col] = big_match_table_df[col].str.split(\" \").str[0]\n",
    "\n",
    "    # clean round 2 and 3\n",
    "    big_match_table_df['round_2'] = big_match_table_df['round_2'].str.replace(r\"[?]\", \"0\", regex=True)\n",
    "    big_match_table_df['round_3'] = big_match_table_df['round_3'].str.replace(r\"[\\[\\]]\", \"\", regex=True)\n",
    "\n",
    "    big_match_table_df['winner_outcome'] = 1\n",
    "    big_match_table_df['loser_outcome'] = 0\n",
    "\n",
    "    return big_match_table_df\n",
    "\n",
    "# ( First script; create a matches table )\n",
    "\n",
    "# create folder if it does not exist\n",
    "os.makedirs(\"atp_transformed\", exist_ok=True)\n",
    "\n",
    "# call the function for each year we want to look at (we can extend this if needed)\n",
    "used_dfs = [create_match_table(year) for year in range(2000, 2025)]\n",
    "\n",
    "# concatenate all years after 1999 up to the given year into a single DataFrame\n",
    "df_post_1999 = pd.concat(used_dfs, ignore_index=True)\n",
    "\n",
    "# ddf = calculate_elo(df_post_1999,K=32)\n",
    "# all_player_elo = pd.concat([ddf[\"winner_elo_pre_match\"], ddf[\"loser_elo_pre_match\"]], ignore_index=True)\n",
    "\n",
    "# plt.hist(all_player_elo,bins=300)\n",
    "\n",
    "# now check if a player has their career cut short due to how splitting was handled by first calling the function for the years that were left out\n",
    "unused_dfs = [create_match_table(year) for year in range(1968, 2000)]\n",
    "\n",
    "# Concatenate all years into a single DataFrame\n",
    "df_pre_2000 = pd.concat(unused_dfs, ignore_index=True)\n",
    "\n",
    "# get all ids from before 2000\n",
    "ids_pre_2000 = df_pre_2000[\"winner_id\"] + df_pre_2000[\"loser_id\"]\n",
    "ids_pre_2000 = ids_pre_2000.drop_duplicates(keep='last')\n",
    "list_of_ids_pre_2000 = ids_pre_2000.to_list()\n",
    "\n",
    "# include pre-2000 matches for players who started before the year 2000\n",
    "df_early = df_pre_2000[\n",
    "    df_pre_2000[\"winner_id\"].isin(list_of_ids_pre_2000) |\n",
    "    df_pre_2000[\"loser_id\"].isin(list_of_ids_pre_2000)\n",
    "]\n",
    "\n",
    "# combine datasets\n",
    "match_table_df = pd.concat([df_early, df_post_1999], ignore_index=True)\n",
    "\n",
    "# format date to have proper date format\n",
    "match_table_df[\"tourney_date\"] = pd.to_datetime(match_table_df[\"tourney_date\"].astype(str), format=\"%Y%m%d\")\n",
    "\n",
    "# sort by date\n",
    "match_table_df = match_table_df.sort_values(\"tourney_date\")\n",
    "\n",
    "# create unique match ids\n",
    "match_table_df['tourney_match_id'] = match_table_df['tourney_id'].astype(str) + ':' + match_table_df['match_num'].astype(str)\n",
    "match_table_df['winner_tourney_match_id'] = match_table_df['winner_id'].astype(str) + ':' + match_table_df['tourney_id'].astype(str) + ':' + match_table_df['match_num'].astype(str)\n",
    "match_table_df['loser_tourney_match_id'] = match_table_df['loser_id'].astype(str) + ':' + match_table_df['tourney_id'].astype(str) + ':' + match_table_df['match_num'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ab249",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_elo(match_df, initial_elo=1500, K=32):\n",
    "    \"\"\"\n",
    "    Calculate Elo ratings and return a match-level DataFrame\n",
    "    with both pre- and post-match Elos.\n",
    "    \"\"\"\n",
    "    player_elos = {}\n",
    "\n",
    "    # Initialize new columns\n",
    "    match_df['winner_elo_pre_match'] = np.nan\n",
    "    match_df['loser_elo_pre_match'] = np.nan\n",
    "    match_df['winner_elo_post_match'] = np.nan\n",
    "    match_df['loser_elo_post_match'] = np.nan\n",
    "\n",
    "    # Ensure chronological order\n",
    "    match_df = match_df.sort_values([\"tourney_date\", \"match_num\"])\n",
    "\n",
    "    for idx, row in match_df.iterrows():\n",
    "\n",
    "        winner = row['winner_id']\n",
    "        loser = row['loser_id']\n",
    "\n",
    "        # Current Elo (or initialize)\n",
    "        R_w = player_elos.get(winner, initial_elo)\n",
    "        R_l = player_elos.get(loser, initial_elo)\n",
    "\n",
    "        # Store pre-match Elos\n",
    "        match_df.at[idx, 'winner_elo_pre_match'] = R_w\n",
    "        match_df.at[idx, 'loser_elo_pre_match'] = R_l\n",
    "\n",
    "        # Expected score\n",
    "        E_w = 1 / (1 + 10 ** ((R_l - R_w) / 400))\n",
    "\n",
    "        # Actual scores (winner=1, loser=0)\n",
    "        S_w = 1\n",
    "        S_l = 0\n",
    "\n",
    "        # Update Elo\n",
    "        R_w_new = R_w + K * (S_w - E_w)\n",
    "        R_l_new = R_l + K * (S_l - (1 - E_w))\n",
    "\n",
    "        # Store post-match Elos\n",
    "        match_df.at[idx, 'winner_elo_post_match'] = R_w_new\n",
    "        match_df.at[idx, 'loser_elo_post_match'] = R_l_new\n",
    "\n",
    "        # Save updated values back to dictionary\n",
    "        player_elos[winner] = R_w_new\n",
    "        player_elos[loser] = R_l_new\n",
    "\n",
    "    return match_df\n",
    "\n",
    "\n",
    "#  # # --------------------------------------------------------------------- ( ELO Calculation )-----------------------------------------------------------------------------------------\n",
    "\n",
    "# calculate the elo\n",
    "match_table_incl_elo_df = calculate_elo(match_table_df,K=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68c755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_table_incl_elo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b67483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ( call function; encode the columns and get the difference, avg diff and avg tiebreak score )\n",
    "\n",
    "all_rounds_cols = [\"round_1\", \"round_2\", \"round_3\", \"round_4\", \"round_5\"]\n",
    "\n",
    "for col in all_rounds_cols:\n",
    "    # Split by '-' into winner and loser scores\n",
    "    split_scores = match_table_incl_elo_df[col].str.split(\"-\", n=1, expand=True)\n",
    "    \n",
    "    # Assign winner and loser columns\n",
    "    match_table_incl_elo_df[f\"{col}_w\"] = split_scores[0]\n",
    "    match_table_incl_elo_df[f\"{col}_l\"] = split_scores[1]\n",
    "\n",
    "def process_round(df, round_col):\n",
    "    w = df[f\"{round_col}_w\"]\n",
    "    l = df[f\"{round_col}_l\"]\n",
    "\n",
    "    # Extract score + tiebreak\n",
    "    w_parts = w.astype(\"string\").str.extract(r'(?P<score>\\d+)(?:\\((?P<tb>\\d+)\\))?')\n",
    "    l_parts = l.astype(\"string\").str.extract(r'(?P<score>\\d+)(?:\\((?P<tb>\\d+)\\))?')\n",
    "\n",
    "    w_score = pd.to_numeric(w_parts[\"score\"], errors=\"coerce\")\n",
    "    l_score = pd.to_numeric(l_parts[\"score\"], errors=\"coerce\")\n",
    "\n",
    "    w_tb = pd.to_numeric(w_parts[\"tb\"], errors=\"coerce\")\n",
    "    l_tb = pd.to_numeric(l_parts[\"tb\"], errors=\"coerce\")\n",
    "\n",
    "    # --- Case 1: winner has explicit tiebreak ---\n",
    "    mask_w_tb = w_tb.notna()\n",
    "    l_tb = l_tb.where(~mask_w_tb, w_tb - 2)\n",
    "\n",
    "    # --- Case 2: loser has explicit tiebreak ---\n",
    "    mask_l_tb = l_tb.notna() & w_tb.isna()\n",
    "    w_tb = w_tb.where(~mask_l_tb, l_tb + 2)\n",
    "\n",
    "    # --- Case 3: scores >= 8, no explicit tiebreak ---\n",
    "    mask_cap = w_tb.isna() & l_tb.isna() & ((w_score >= 8) | (l_score >= 8))\n",
    "\n",
    "    w_wins = mask_cap & (w_score > l_score)\n",
    "    l_wins = mask_cap & (l_score > w_score)\n",
    "\n",
    "    w_tb = w_tb.where(~w_wins, w_score - 7)\n",
    "    l_tb = l_tb.where(~w_wins, (w_tb - 2).clip(lower=0))\n",
    "\n",
    "    l_tb = l_tb.where(~l_wins, l_score - 7)\n",
    "    w_tb = w_tb.where(~l_wins, (l_tb - 2).clip(lower=0))\n",
    "\n",
    "    w_score = w_score.where(~w_wins, 7)\n",
    "    l_score = l_score.where(~w_wins, 6)\n",
    "\n",
    "    l_score = l_score.where(~l_wins, 7)\n",
    "    w_score = w_score.where(~l_wins, 6)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        f\"{round_col}_w_numb\": w_score,\n",
    "        f\"{round_col}_w_tb_numb\": w_tb,\n",
    "        f\"{round_col}_l_numb\": l_score,\n",
    "        f\"{round_col}_l_tb_numb\": l_tb,\n",
    "    })\n",
    "\n",
    "round_frames = [\n",
    "    process_round(match_table_incl_elo_df, round_col)\n",
    "    for round_col in all_rounds_cols\n",
    "]\n",
    "\n",
    "# convert all to numeric before merging with main df\n",
    "numeric_scores = pd.concat(round_frames, axis=1)\n",
    "numeric_scores = numeric_scores.apply(pd.to_numeric, errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# add numeric scores to old df\n",
    "match_table_incl_elo_df = pd.concat([match_table_incl_elo_df,numeric_scores],axis=1)\n",
    "\n",
    "# compute the difference per round and tiebreak\n",
    "r_number_types = [\"numb\", \"tb_numb\"]\n",
    "for r in all_rounds_cols:\n",
    "    for t in r_number_types:\n",
    "        w_col = f\"{r}_w_{t}\"\n",
    "        l_col = f\"{r}_l_{t}\"\n",
    "        \n",
    "        # create winner difference\n",
    "        diff_w_col = f\"{r}_w_diff\" if t == \"numb\" else f\"{r}_w_tb_diff\"\n",
    "        match_table_incl_elo_df[diff_w_col] = match_table_incl_elo_df[w_col] - match_table_incl_elo_df[l_col]\n",
    "\n",
    "        # create loser difference\n",
    "        diff_l_col = f\"{r}_l_diff\" if t == \"numb\" else f\"{r}_l_tb_diff\"\n",
    "        match_table_incl_elo_df[diff_l_col] = -match_table_incl_elo_df[diff_w_col]\n",
    "\n",
    "# create mean, median and total scores over the rounds for winner and loser\n",
    "suffixes = [\"w_numb\", \"l_numb\",\"w_diff\", \"l_diff\", \"w_tb_numb\", \"l_tb_numb\", \"w_tb_diff\", \"l_tb_diff\"]\n",
    "for suffix in suffixes:\n",
    "    # select all rounds\n",
    "    cols = match_table_incl_elo_df.filter(regex=fr'round_\\d+_{suffix}$').columns\n",
    "\n",
    "    match_table_incl_elo_df[f\"mean_{suffix}\"] = match_table_incl_elo_df[cols].mean(axis=1, skipna=True)\n",
    "    match_table_incl_elo_df[f\"median_{suffix}\"] = match_table_incl_elo_df[cols].median(axis=1, skipna=True)\n",
    "    match_table_incl_elo_df[f\"total_{suffix}\"] = match_table_incl_elo_df[cols].sum(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_player_table(df):\n",
    "    shared_player_columns = [\n",
    "    'tourney_id', 'tourney_name', 'surface', 'draw_size', 'tourney_level', \n",
    "    'tourney_date', 'match_num', 'score', 'best_of', \n",
    "    'tourney_round', 'minutes', 'tourney_type', \n",
    "    #'round_1', 'round_2', 'round_3', 'round_4', 'round_5', this is causing duplicates and is not needed after extracting the individual scores \n",
    "    'tourney_match_id'\n",
    "    ]\n",
    "\n",
    "    # shared columns for winner and loser\n",
    "    base_cols = df[shared_player_columns]\n",
    "\n",
    "    # winner only stats \n",
    "    winner_df = pd.concat([\n",
    "        base_cols,\n",
    "        df[['winner_id', 'winner_tourney_match_id', \n",
    "            'winner_seed', 'winner_entry', 'winner_name', 'winner_hand', 'winner_ht', 'winner_ioc', 'winner_age', \n",
    "            'w_ace', 'w_df', 'w_svpt', 'w_1stIn', 'w_1stWon', 'w_2ndWon', 'w_SvGms', 'w_bpSaved', 'w_bpFaced', \n",
    "            'winner_rank', 'winner_rank_points', 'winner_elo_pre_match', 'winner_outcome','loser_id', 'loser_elo_pre_match', 'loser_rank',\n",
    "            'round_1_w', 'round_2_w', 'round_3_w', 'round_4_w', 'round_5_w', 'winner_elo_post_match',\n",
    "            'round_1_w_numb', 'round_1_w_tb_numb', \n",
    "            'round_2_w_numb', 'round_2_w_tb_numb', \n",
    "            'round_3_w_numb', 'round_3_w_tb_numb', \n",
    "            'round_4_w_numb', 'round_4_w_tb_numb', \n",
    "            'round_5_w_numb', 'round_5_w_tb_numb', \n",
    "            'round_1_w_diff', 'round_1_w_tb_diff', \n",
    "            'round_2_w_diff', 'round_2_w_tb_diff', \n",
    "            'round_3_w_diff', 'round_3_w_tb_diff', \n",
    "            'round_4_w_diff', 'round_4_w_tb_diff', \n",
    "            'round_5_w_diff', 'round_5_w_tb_diff', \n",
    "            'mean_w_numb', 'median_w_numb', 'total_w_numb', \n",
    "            'mean_w_diff', 'median_w_diff', 'total_w_diff', \n",
    "            'mean_w_tb_numb', 'median_w_tb_numb', 'total_w_tb_numb', \n",
    "            'mean_w_tb_diff', 'median_w_tb_diff', 'total_w_tb_diff']]\n",
    "            ], axis=1)\n",
    "\n",
    "    # Rename columns to standard names if needed\n",
    "    winner_df = winner_df.rename(columns={\n",
    "        'winner_id':'player_id', 'winner_tourney_match_id':'player_tourney_match_id', 'winner_seed':'player_seed', 'winner_entry':'player_entry', 'winner_name':'player_name',\n",
    "        'winner_hand':'player_hand', 'winner_ht':'player_height', 'winner_ioc':'player_country','loser_id':'opponent_id', 'loser_elo_pre_match':'opponent_elo_pre_match', \n",
    "        'loser_rank':'opponent_rank', \n",
    "        'w_ace':'ace', 'w_df':'double_faults', 'w_svpt':'points_on_serve', 'w_1stIn':'first_serve_in', \n",
    "        'w_1stWon':'1stWon', 'w_2ndWon':'2ndWon', 'w_SvGms':'service_games', 'winner_elo_post_match':'elo_post_match',\n",
    "        'w_bpSaved':'break_points_saved', 'w_bpFaced':'break_points_faced',\n",
    "        'winner_age':'player_age', 'winner_rank':'player_rank', 'winner_rank_points':'player_rank_points',\n",
    "        'winner_elo_pre_match':'elo_pre_match', 'winner_outcome':'match_outcome' ,'round_1_w':'round_1', 'round_2_w':'round_2', \n",
    "        'round_3_w':'round_3', 'round_4_w':'round_4', 'round_5_w':'round_5', \n",
    "        'round_1_w_numb':'round_1_numb', 'round_1_w_tb_numb':'round_1_tb_numb', 'round_2_w_numb':'round_2_numb', \n",
    "        'round_2_w_tb_numb':'round_2_tb_numb', 'round_3_w_numb':'round_3_numb', \n",
    "        'round_3_w_tb_numb':'round_3_tb_numb', 'round_4_w_numb':'round_4_numb', \n",
    "        'round_4_w_tb_numb':'round_4_tb_numb', 'round_5_w_numb':'round_5_numb', \n",
    "        'round_5_w_tb_numb':'round_5_tb_numb', 'round_1_w_diff':'round_1_diff', \n",
    "        'round_1_w_tb_diff':'round_1_tb_diff', 'round_2_w_diff':'round_2_diff', \n",
    "        'round_2_w_tb_diff':'round_2_tb_diff', 'round_3_w_diff':'round_3_diff', \n",
    "        'round_3_w_tb_diff':'round_3_tb_diff', 'round_4_w_diff':'round_4_diff', \n",
    "        'round_4_w_tb_diff':'round_4_tb_diff', 'round_5_w_diff':'round_5_diff', \n",
    "        'round_5_w_tb_diff':'round_5_tb_diff', 'mean_w_numb':'mean_numb', 'median_w_numb':'median_numb', \n",
    "        'total_w_numb':'total_numb', 'mean_w_diff':'mean_diff', 'median_w_diff':'median_diff', \n",
    "        'total_w_diff':'total_diff', 'mean_w_tb_numb':'mean_tb_numb', 'median_w_tb_numb':'median_tb_numb', \n",
    "        'total_w_tb_numb':'total_tb_numb', 'mean_w_tb_diff':'mean_tb_diff', 'median_w_tb_diff':'median_tb_diff', \n",
    "        'total_w_tb_diff':'total_tb_diff'\n",
    "    })\n",
    "\n",
    "    # loser only stats \n",
    "    loser_df = pd.concat([\n",
    "        base_cols,\n",
    "        df[['loser_id', 'loser_tourney_match_id', \n",
    "            'loser_seed', 'loser_entry', 'loser_name', 'loser_hand', 'loser_ht', 'loser_ioc', 'loser_age', \n",
    "            'l_ace', 'l_df', 'l_svpt', 'l_1stIn', 'l_1stWon', 'l_2ndWon', 'l_SvGms', 'l_bpSaved', 'l_bpFaced', \n",
    "            'loser_rank', 'loser_rank_points', 'loser_elo_pre_match', 'loser_outcome', 'winner_id', 'winner_elo_pre_match', 'winner_rank',\n",
    "            'round_1_l', 'round_2_l', 'round_3_l', 'round_4_l', 'round_5_l', 'loser_elo_post_match',\n",
    "            'round_1_l_numb', 'round_1_l_tb_numb', \n",
    "            'round_2_l_numb', 'round_2_l_tb_numb', \n",
    "            'round_3_l_numb', 'round_3_l_tb_numb', \n",
    "            'round_4_l_numb', 'round_4_l_tb_numb', \n",
    "            'round_5_l_numb', 'round_5_l_tb_numb',\n",
    "            'round_1_l_diff', 'round_1_l_tb_diff', \n",
    "            'round_2_l_diff', 'round_2_l_tb_diff', \n",
    "            'round_3_l_diff', 'round_3_l_tb_diff', \n",
    "            'round_4_l_diff', 'round_4_l_tb_diff', \n",
    "            'round_5_l_diff', 'round_5_l_tb_diff', \n",
    "            'mean_l_numb', 'median_l_numb', 'total_l_numb', \n",
    "            'mean_l_diff', 'median_l_diff', 'total_l_diff', \n",
    "            'mean_l_tb_numb', 'median_l_tb_numb', 'total_l_tb_numb', \n",
    "            'mean_l_tb_diff', 'median_l_tb_diff', 'total_l_tb_diff']]\n",
    "            ],axis=1)\n",
    "\n",
    "    loser_df = loser_df.rename(columns={\n",
    "        'loser_id':'player_id', 'loser_tourney_match_id':'player_tourney_match_id', 'loser_seed':'player_seed', 'loser_entry':'player_entry', 'loser_name':'player_name',\n",
    "        'loser_hand':'player_hand', 'loser_ht':'player_height', 'loser_ioc':'player_country', 'winner_id':'opponent_id', 'winner_elo_pre_match':'opponent_elo_pre_match', \n",
    "        'winner_rank':'opponent_rank',\n",
    "        'l_ace':'ace', 'l_df':'double_faults', 'l_svpt':'points_on_serve', 'l_1stIn':'first_serve_in', 'l_1stWon':'1stWon', \n",
    "        'l_2ndWon':'2ndWon','l_SvGms':'service_games', 'l_bpSaved':'break_points_saved', 'l_bpFaced':'break_points_faced', \n",
    "        'loser_age':'player_age', 'loser_rank':'player_rank', 'loser_rank_points':'player_rank_points', 'loser_elo_post_match':'elo_post_match',\n",
    "        'loser_elo_pre_match':'elo_pre_match', 'loser_outcome':'match_outcome', 'round_1_l':'round_1', 'round_2_l':'round_2', \n",
    "        'round_3_l':'round_3', 'round_4_l':'round_4', 'round_5_l':'round_5', 'round_1_l_numb':'round_1_numb', \n",
    "        'round_1_l_tb_numb':'round_1_tb_numb', 'round_2_l_numb':'round_2_numb', 'round_2_l_tb_numb':'round_2_tb_numb',\n",
    "        'round_3_l_numb':'round_3_numb', 'round_3_l_tb_numb':'round_3_tb_numb', 'round_4_l_numb':'round_4_numb', \n",
    "        'round_4_l_tb_numb':'round_4_tb_numb', 'round_5_l_numb':'round_5_numb', 'round_5_l_tb_numb':'round_5_tb_numb', \n",
    "        'round_1_l_diff':'round_1_diff', 'round_1_l_tb_diff':'round_1_tb_diff', 'round_2_l_diff':'round_2_diff', \n",
    "        'round_2_l_tb_diff':'round_2_tb_diff', 'round_3_l_diff':'round_3_diff', 'round_3_l_tb_diff':'round_3_tb_diff', \n",
    "        'round_4_l_diff':'round_4_diff', 'round_4_l_tb_diff':'round_4_tb_diff', 'round_5_l_diff':'round_5_diff', \n",
    "        'round_5_l_tb_diff':'round_5_tb_diff', 'mean_l_numb':'mean_numb', 'median_l_numb':'median_numb', \n",
    "        'total_l_numb':'total_numb', 'mean_l_diff':'mean_diff', 'median_l_diff':'median_diff', \n",
    "        'total_l_diff':'total_diff', 'mean_l_tb_numb':'mean_tb_numb', 'median_l_tb_numb':'median_tb_numb', \n",
    "        'total_l_tb_numb':'total_tb_numb', 'mean_l_tb_diff':'mean_tb_diff', \n",
    "        'median_l_tb_diff':'median_tb_diff', 'total_l_tb_diff':'total_tb_diff'\n",
    "    })\n",
    "\n",
    "    pivoted_player_table = pd.concat([winner_df, loser_df],axis=0)\n",
    "    return pivoted_player_table\n",
    "\n",
    "#  ( call fuction; pivot the table so that it becomes a per player table )\n",
    "\n",
    "# create the player_table\n",
    "player_table_df = create_player_table(match_table_incl_elo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7582d63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_temporal_values(df):\n",
    "    # Extract tournament year\n",
    "    df[\"year\"] = df[\"tourney_date\"].dt.year\n",
    "\n",
    "    # Find each player's first tournament date\n",
    "    first_tournament = (\n",
    "        df.groupby(\"player_id\")[\"tourney_date\"]\n",
    "        .min()\n",
    "        .rename(\"first_tourney_date\")\n",
    "    )\n",
    "\n",
    "    # Merge back to main dataframe\n",
    "    df = df.merge(first_tournament, on=\"player_id\", how=\"left\")\n",
    "\n",
    "    # Days of experience (exact)\n",
    "    df[\"days_of_experience\"] = (df[\"tourney_date\"] - df[\"first_tourney_date\"]).dt.days\n",
    "\n",
    "    # Months of experience (approximate)\n",
    "    df[\"months_of_experience\"] = df[\"days_of_experience\"] / 30.44  # average month length\n",
    "\n",
    "    # Years of experience (approximate, adjusted for leap years)\n",
    "    df[\"years_of_experience\"] = df[\"days_of_experience\"] / 365.25\n",
    "\n",
    "    # Career year (integer stage of player’s career: 1, 2, 3, …)\n",
    "    # We floor the years and add 1 so first tournaments = Year 1\n",
    "    df[\"career_year\"] = (df[\"years_of_experience\"].apply(int) + 1)\n",
    "\n",
    "    experience_per_year = (\n",
    "        df.groupby([\"player_id\", \"year\"])[\"years_of_experience\"]\n",
    "        .max()                     # latest experience in that year\n",
    "        .reset_index()\n",
    "        .round(0)\n",
    "        .rename(columns={\"years_of_experience\": \"experience\"})\n",
    "    )\n",
    "\n",
    "    temporal_df = df.merge(\n",
    "        experience_per_year,\n",
    "        on=[\"player_id\",\"year\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # drop year because it's not needed anymore\n",
    "    temporal_df = df.drop(columns=\"year\")\n",
    "\n",
    "    # create amount of restdays for restdays between games\n",
    "    temporal_df = temporal_df.sort_values(['player_id', 'tourney_date', 'match_num'])\n",
    "    temporal_df['rest_days'] = temporal_df.groupby('player_id')['tourney_date'].diff().dt.days\n",
    "    \n",
    "    return temporal_df\n",
    "\n",
    "# -------------------------------------------------- ( call fuction; add days, months and years of experience ) --------------------------------------------------\n",
    "\n",
    "player_table_df = add_temporal_values(player_table_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708c34a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_tourney_round(df):\n",
    "    r = df['tourney_round']\n",
    "\n",
    "    # Initialize output series\n",
    "    finish = pd.Series(np.nan, index=df.index)\n",
    "\n",
    "    # ------ MAIN DRAW ------\n",
    "    main_map = {\n",
    "        'SF': 3,\n",
    "        'QF': 5,\n",
    "        'R16': 9,\n",
    "        'R32': 17,\n",
    "        'R64': 33,\n",
    "        'R128': 65,\n",
    "        'RR': np.nan\n",
    "    }\n",
    "    for key, val in main_map.items():\n",
    "        finish[r == key] = val\n",
    "\n",
    "    # ------ FINAL ------\n",
    "    is_final = (r == 'F')\n",
    "    if 'match_outcome' in df.columns:\n",
    "        finish.loc[is_final & (df['match_outcome'] == 1)] = 1\n",
    "        finish.loc[is_final & (df['match_outcome'] != 1)] = 2\n",
    "\n",
    "    # ------ BRONZE ------\n",
    "    is_br = (r == 'BR')\n",
    "    finish.loc[is_br & (df['match_outcome'] == 1)] = 3\n",
    "    finish.loc[is_br & (df['match_outcome'] != 1)] = 4\n",
    "\n",
    "    # ------ QUALIFYING (Q1–Qn) ------\n",
    "    q_mask = r.str.match(r\"Q\\d+\")\n",
    "    q_round_num = r.where(q_mask).str.extract(r\"Q(\\d+)\").astype(float).iloc[:, 0]\n",
    "\n",
    "    # Use per-row draw size for qualifying rounds\n",
    "    qualifying_draw = df['draw_size'].where(q_mask)\n",
    "\n",
    "    # Compute players at round start\n",
    "    players_at_round_start = qualifying_draw / (2 ** (q_round_num - 1))\n",
    "\n",
    "    # Finish position = second half of players remaining\n",
    "    finish.loc[q_mask] = (players_at_round_start / 2 + 1).astype(float)\n",
    "\n",
    "    return finish\n",
    "\n",
    "# --------------------------------------------------------------------- ( call fuction; encode rounds ) ---------------------------------------------------------------------\n",
    "\n",
    "player_table_df['finish_position'] = encode_tourney_round(player_table_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86da4159",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in all_rounds_cols:\n",
    "    player_table_df[f'{n}_outcome'] = (\n",
    "        player_table_df[f'{n}_diff'] > 0\n",
    "    ).astype(\"Int64\")   # nullable integer dtype\n",
    "    \n",
    "    player_table_df[f'{n}_tb_outcome'] = (\n",
    "        player_table_df[f'{n}_tb_diff'] > 0\n",
    "    ).astype(\"Int64\")   # nullable integer dtype\n",
    "\n",
    "player_table_df['sets_won'] = player_table_df[['round_1_outcome','round_2_outcome','round_3_outcome','round_4_outcome','round_5_outcome']].sum(axis=1, skipna=True)\n",
    "player_table_df['sets_lost'] = player_table_df[['round_1_outcome','round_2_outcome','round_3_outcome','round_4_outcome','round_5_outcome']].count(axis=1) - player_table_df['sets_won']\n",
    "\n",
    "player_table_df['tb_sets_won'] = player_table_df[['round_1_tb_outcome','round_2_tb_outcome','round_3_tb_outcome','round_4_tb_outcome','round_5_tb_outcome']].sum(axis=1, skipna=True)\n",
    "player_table_df['tb_sets_lost'] = player_table_df[['round_1_tb_outcome','round_2_tb_outcome','round_3_tb_outcome','round_4_tb_outcome','round_5_tb_outcome']].count(axis=1) - player_table_df['tb_sets_won']\n",
    "\n",
    "player_table_df['set_dominance'] = player_table_df['sets_won'] / (player_table_df['sets_lost'] + player_table_df['sets_won'])\n",
    "player_table_df['tb_dominance'] = player_table_df['tb_sets_won'] / (player_table_df['tb_sets_lost'] + player_table_df['tb_sets_won'])\n",
    "\n",
    "# get the highest round reached within a tournament\n",
    "min_round_df = (\n",
    "    player_table_df\n",
    "    .groupby(['player_id', 'tourney_id'], as_index=False)\n",
    "    ['finish_position']\n",
    "    .min()\n",
    ")\n",
    "min_round_df = min_round_df.rename(columns={'finish_position':'highest_finish_position'})\n",
    "\n",
    "# join the table together\n",
    "player_table_df = player_table_df.merge(\n",
    "    min_round_df,\n",
    "    on=['player_id', 'tourney_id']\n",
    ")\n",
    "# assign which columns should get a rolling variant\n",
    "numeric_median_columns = [\n",
    "    'minutes', 'draw_size','finish_position','highest_finish_position'\n",
    "]\n",
    "numeric_mean_columns = [\n",
    "    'ace', 'double_faults','points_on_serve', 'first_serve_in', \n",
    "    '1stWon', '2ndWon','service_games', 'break_points_saved', 'break_points_faced', \n",
    "    'elo_pre_match', 'opponent_elo_pre_match','set_dominance','tb_dominance','player_rank', 'mean_numb', \n",
    "    'median_numb', 'total_numb', 'mean_diff', 'median_diff', 'total_diff', 'mean_tb_numb', 'median_tb_numb', \n",
    "    'total_tb_numb', 'mean_tb_diff', 'median_tb_diff', 'total_tb_diff'\n",
    "\n",
    "]\n",
    "\n",
    "# sort by chronological order\n",
    "player_table_df = player_table_df.sort_values(['player_id', 'days_of_experience','match_num'])\n",
    "\n",
    "for col in numeric_median_columns + numeric_mean_columns:\n",
    "    player_table_df[col] = pd.to_numeric(player_table_df[col], errors='coerce')\n",
    "\n",
    "g = player_table_df.groupby('player_id', sort=False)\n",
    "\n",
    "for col in numeric_median_columns:\n",
    "    player_table_df[f\"{col}_rolling_med_10\"] = (\n",
    "        g[col]\n",
    "        .shift()\n",
    "        .rolling(10, min_periods=1)\n",
    "        .median()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "for col in numeric_mean_columns:\n",
    "    player_table_df[f\"{col}_rolling_mean_10\"] = (\n",
    "        g[col]\n",
    "        .shift()\n",
    "        .rolling(10, min_periods=1)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    # create the target\n",
    "player_table_df['elo'] = (\n",
    "    player_table_df.groupby('player_id')['elo_pre_match']\n",
    "    .shift(-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea31f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates\n",
    "player_table_df = player_table_df.loc[:, ~player_table_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36782e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataframe info\n",
    "player_table_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a0c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "player_table_df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff2074e",
   "metadata": {},
   "source": [
    "## surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc375aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = player_table_df['surface'].value_counts(dropna=False)\n",
    "\n",
    "# Different types of surfaces\n",
    "print(\"Value counts for 'surface' column:\")\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf62448",
   "metadata": {},
   "source": [
    "### Dropping the 106 records with null surface \n",
    "It's a very low percentage of the data and will be dropped as surface cannot be guessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edbf6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_table_df = player_table_df.loc[~player_table_df['surface'].isnull()].copy()   # keeps rows where player_age is NOT null\n",
    "\n",
    "# --- Verify removal ---\n",
    "null_count = player_table_df['surface'].isnull().sum()\n",
    "\n",
    "print(\"Number of rows with missing surface AFTER drop:\", null_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c56b73",
   "metadata": {},
   "source": [
    "## score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f27dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_score_count = player_table_df.loc[player_table_df['score'].isnull()].shape[0]\n",
    "\n",
    "print(\"Missing score:\", missing_score_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a344f74",
   "metadata": {},
   "source": [
    "### Dropping the 100 records with null score \n",
    "It's a very low percentage of the data, score is necessary to know the outcome of a match will be dropped as surface cannot be guessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13178e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_table_df = player_table_df.loc[~player_table_df['score'].isnull()].copy()   # keeps rows where score is NOT null\n",
    "\n",
    "# --- Verify removal ---\n",
    "null_count = player_table_df['score'].isnull().sum()\n",
    "\n",
    "print(\"Number of rows with missing score AFTER drop:\", null_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef536d58",
   "metadata": {},
   "source": [
    "## round_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df1c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_round1_count = player_table_df[player_table_df['round_1'].isna()].shape[0]\n",
    "\n",
    "print(\"Amount of records with null round_1:\", null_round1_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c2a82d",
   "metadata": {},
   "source": [
    "### Dropping the 70 records with null round_1 \n",
    "It's a very low percentage of the data, round_1 is necessary to be sure a match was actually played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab3e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_table_df = player_table_df.loc[~player_table_df['round_1'].isnull()].copy()   # keeps rows where round_1 is NOT null\n",
    "\n",
    "# --- Verify removal ---\n",
    "null_count = player_table_df['round_1'].isnull().sum()\n",
    "\n",
    "print(\"Number of rows with missing round_1 AFTER drop:\", null_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ea8d3b",
   "metadata": {},
   "source": [
    "### round_2 round_3 round_4 round_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572998da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['score','round_1','round_2','round_3','round_4','round_5']\n",
    "missing = player_table_df[cols].isna().sum()\n",
    "print(missing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd27c217",
   "metadata": {},
   "source": [
    "### Filling the remaining round records with NaN values\n",
    "\n",
    "A lot of these rounds should be NaN because not every match consists of 5 rounds of play, these will be filled with 'N/A'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd89989",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_cols = ['round_2', 'round_3', 'round_4', 'round_5']\n",
    "player_table_df[round_cols] = player_table_df[round_cols].fillna('N/A')\n",
    "\n",
    "# --- Verify removal ---\n",
    "missing = player_table_df[cols].isna().sum()\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3e217a",
   "metadata": {},
   "source": [
    "## player_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918efc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_age_ids_count = player_table_df.loc[player_table_df['player_age'].isnull()].shape[0]\n",
    "missing_rank_ids_count = player_table_df.loc[player_table_df['player_rank'].isnull()].shape[0]\n",
    "missing_age_and_rank_ids = player_table_df.loc[player_table_df['player_age'].isnull() & player_table_df['player_rank'].isnull()].shape[0]\n",
    "\n",
    "print(\"Missing player_age:\", missing_age_ids_count)\n",
    "print(\"Missing player_rank:\", missing_rank_ids_count)\n",
    "print(\"Missing both player_age and player_rank:\", missing_age_and_rank_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f10d75",
   "metadata": {},
   "source": [
    "### Dropping the 2962 records with null player_ages and player_rank\n",
    "\n",
    "These records miss valuable information and will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c563c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing before dropping\n",
    "missing_age_and_rank_ids = player_table_df.loc[\n",
    "    player_table_df['player_age'].isnull() & player_table_df['player_rank'].isnull()\n",
    "].shape[0]\n",
    "\n",
    "print(\"Missing both player_age and player_rank BEFORE drop:\", missing_age_and_rank_ids)\n",
    "\n",
    "# --- Drop rows where BOTH player_age and player_rank are null ---\n",
    "player_table_df = player_table_df.dropna(subset=['player_age', 'player_rank'], how='all') \n",
    "\n",
    "# Check again after dropping\n",
    "missing_age_and_rank_ids_after = player_table_df.loc[\n",
    "    player_table_df['player_age'].isnull() & player_table_df['player_rank'].isnull()\n",
    "].shape[0]\n",
    "\n",
    "print(\"Missing both player_age and player_rank AFTER drop:\", missing_age_and_rank_ids_after)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4896b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_age_ids_count = player_table_df.loc[player_table_df['player_age'].isnull()].shape[0]\n",
    "\n",
    "print(\"Missing player_age:\", missing_age_ids_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca73ced8",
   "metadata": {},
   "source": [
    "### Dropping the remaining 1675 records with null player_ages\n",
    "\n",
    "Even though these records do contain_player rank, they miss a lot of valuable columns so we are going to drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01912ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_table_df = player_table_df.loc[~player_table_df['player_age'].isnull()].copy()   # keeps rows where player_age is NOT null\n",
    "\n",
    "# --- Verify removal ---\n",
    "missing_age_rows_after = player_table_df.loc[player_table_df['player_age'].isnull()].shape[0]\n",
    "\n",
    "print(\"Number of rows with missing player_age AFTER drop:\", missing_age_rows_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e92aba",
   "metadata": {},
   "source": [
    "### player_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d1967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rank_ids_count = player_table_df.loc[player_table_df['player_rank'].isnull()].shape[0]\n",
    "\n",
    "print(\"Missing player_rank:\", missing_rank_ids_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9444ee58",
   "metadata": {},
   "source": [
    "### Dealing with remaining null player_rank records\n",
    "We need these records removed or replaced with max(rank) + 1 in order to have a good target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1dd3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the two lines below to replace nan values with max + 1\n",
    "lowest_player_rank = player_table_df['player_rank'].max() + 1\n",
    "player_table_df['player_rank'] = player_table_df['player_rank'].replace(np.nan,lowest_player_rank)\n",
    "missing_rank_rows_after = player_table_df.loc[player_table_df['player_rank'].isnull()].shape[0]\n",
    "\n",
    "\n",
    "print(\"Number of rows with missing player_rank AFTER drop:\", missing_age_rows_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276e8c9",
   "metadata": {},
   "source": [
    "### Player hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602da1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_table_df['player_hand'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fddf1f8",
   "metadata": {},
   "source": [
    "### Filling the NaN player_hand records with U\n",
    "\n",
    "What we don't know we fill with 'U' for unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_table_df['player_hand'] = player_table_df['player_hand'].replace({'L': 1, 'R': 2})\n",
    "\n",
    "# Create missing flag\n",
    "player_table_df['player_hand_missing'] = player_table_df['player_hand'].isna().astype(int)\n",
    "\n",
    "#  Fill missing values with 'U' (Unknown)\n",
    "player_table_df['player_hand'] = player_table_df['player_hand'].fillna('U')\n",
    "\n",
    "# Normalize all codes to readable text\n",
    "player_table_df['player_hand'] = player_table_df['player_hand'].replace({\n",
    "    'R': 'Right',\n",
    "    'L': 'Left',\n",
    "    'U': 'Unknown',\n",
    "    'A': 'Ambidextrous'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e04687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open in data wrangler\n",
    "player_table_df\n",
    "\n",
    "# Save cleaned dataframe to new CSV (comment out to have it work)\n",
    "# # export tables as csv files\n",
    "player_table_df.to_csv(BASE_DIR / \"atp_transformed\" / f\"2000-2024 players_3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68312ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "player_table_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744708b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ( vizualisation below. technically not needed in the pipeline )\n",
    "\n",
    "# make a copy of the player_table to visualise\n",
    "median_df = player_table_df.copy()\n",
    "\n",
    "# Bin experience into 30-day intervals\n",
    "median_df['days_bin'] = (median_df['days_of_experience'] // 30) * 30\n",
    "\n",
    "# compute median Elo and rank per bin; calculate a median for every 30 days\n",
    "median_curve = median_df.groupby('days_bin')['elo_pre_match'].median().reset_index(name='median_elo')\n",
    "\n",
    "# compute 25th and 75th percentiles for shading to show how much variance there is between elo and player rank\n",
    "q25_elo = median_df.groupby('days_bin')['elo_pre_match'].quantile(0.25).reset_index(name='q25_elo')\n",
    "q75_elo = median_df.groupby('days_bin')['elo_pre_match'].quantile(0.75).reset_index(name='q75_elo')\n",
    "\n",
    "# merge into one DataFrame\n",
    "median_curve = median_curve.merge(q25_elo, on='days_bin').merge(q75_elo, on='days_bin')\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(median_curve['days_bin'], median_curve['median_elo'], color='blue', label='Median Elo')\n",
    "plt.fill_between(median_curve['days_bin'], median_curve['q25_elo'], median_curve['q75_elo'], color='blue', alpha=0.2, label='25-75 percentile')\n",
    "plt.xlabel('Days of Experience')\n",
    "plt.ylabel('Elo (pre-match)')\n",
    "plt.title('Median Elo Progression Across All Players')\n",
    "plt.legend()\n",
    "plt.margins(x=0)\n",
    "#plt.show()\n",
    "\n",
    "# do the same for player rank\n",
    "median_rank = median_df.groupby('days_bin')['player_rank'].median().reset_index(name='median_rank')\n",
    "q25_rank = median_df.groupby('days_bin')['player_rank'].quantile(0.25).reset_index(name='q25_rank')\n",
    "q75_rank = median_df.groupby('days_bin')['player_rank'].quantile(0.75).reset_index(name='q75_rank')\n",
    "\n",
    "median_curve = (\n",
    "    median_rank\n",
    "    .merge(q25_rank, on='days_bin')\n",
    "    .merge(q75_rank, on='days_bin')\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(median_curve['days_bin'], median_curve['median_rank'], color='blue', label='Median Rank')\n",
    "plt.fill_between(median_curve['days_bin'], median_curve['q25_rank'], median_curve['q75_rank'], color='blue', alpha=0.2, label='25-75 percentile')\n",
    "plt.xlabel('Days of Experience')\n",
    "plt.ylabel('Rank (pre-match)')\n",
    "plt.title('Median Rank Progression Across All Players')\n",
    "plt.legend()\n",
    "plt.margins(x=0)\n",
    "plt.gca().invert_yaxis()\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
