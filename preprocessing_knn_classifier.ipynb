{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b62fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv\n",
    "full_df = pd.read_csv('atp_transformed/2000-2024_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b152ac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose features for prediction\n",
    "selected_features = [\n",
    "'tourney_type',\n",
    "'surface',\n",
    "'draw_size',\n",
    "'tourney_level',\n",
    "'match_num',\n",
    "'round_1',\n",
    "'round_2',\n",
    "'round_3',\n",
    "'round_4',\n",
    "'round_5',\n",
    "'best_of',\n",
    "'tourney_round',\n",
    "'minutes',\n",
    "'player_id',\n",
    "'player_seed',\n",
    "'player_hand',\n",
    "'player_height',\n",
    "'player_country',\n",
    "'player_age',\n",
    "'player_rank_points',\n",
    "'ace',\n",
    "'double_faults',\n",
    "'points_on_serve',\n",
    "'first_serve_in',\n",
    "'1st_won',\n",
    "'2nd_won',\n",
    "'service_games',\n",
    "'break_points_saved',\n",
    "'break_points_faced',\n",
    "'match_outcome',\n",
    "'binned_rank' # target\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d4120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all nan values since elo is not integrated in this solution (using elo here would be better so everyone starts at 1500)\n",
    "full_df['player_rank'] = full_df['player_rank'].dropna()\n",
    "\n",
    "bins = (\n",
    "    [0, 1, 2, 3, 4, 6, 11, 21, 31, 41, 51, 101, 151, 201, 251, 301, 401] +\n",
    "    list(range(501, 2501, 100))  # 501-600, 601-700, ..., up to 2401-2500\n",
    ")\n",
    "\n",
    "# Create labels for bins\n",
    "labels = []\n",
    "\n",
    "# Manually for the first ones\n",
    "labels += ['1', '2', '3', '4-5', '6-10', '11-20', '21-30', '31-40', '41-50', '51-100', \n",
    "           '101-150', '151-200', '201-250', '251-300', '301-400', '401-500']\n",
    "\n",
    "# Then dynamically for the 500+ ranges\n",
    "for start in range(501, 2501, 100):\n",
    "    end = min(start + 99, 2500)\n",
    "    labels.append(f'{start}-{end}')\n",
    "\n",
    "# Bin the ranks\n",
    "full_df['binned_rank'] = pd.cut(full_df['player_rank'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d37a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all features to use in the prediction\n",
    "df_subset = full_df[selected_features]\n",
    "\n",
    "# drop all values where nan because knn cannot deal with empty values\n",
    "df_subset = df_subset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8defa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print numeric columns\n",
    "# numeric_cols = df_subset.select_dtypes(exclude=[np.number]).columns\n",
    "# print(numeric_cols)\n",
    "\n",
    "# encode non numeric values\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')  # drop first to avoid multicollinearity\n",
    "surface_encoded = encoder.fit_transform(df_subset[['tourney_type', 'surface', 'tourney_level', 'round_1', 'round_2','round_3', 'round_4', 'round_5', 'tourney_round', 'player_hand', 'player_country']])\n",
    "surface_df = pd.DataFrame(surface_encoded, \n",
    "                          columns=encoder.get_feature_names_out(['tourney_type', 'surface', 'tourney_level', 'round_1', 'round_2','round_3', 'round_4', 'round_5', 'tourney_round', 'player_hand', 'player_country']),\n",
    "                          index=df_subset.index)\n",
    "df_encoded = pd.concat([df_subset.drop(['tourney_type', 'surface', 'tourney_level', 'round_1', 'round_2','round_3', 'round_4', 'round_5', 'tourney_round', 'player_hand', 'player_country'], axis=1), surface_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86677fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "X = df_encoded.drop('binned_rank', axis=1)  # Features\n",
    "y = df_encoded['binned_rank']  # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb30026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2db666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale features to normalise\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e33fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the K as the square root of total rows (this is allegedly a rule of thumb)\n",
    "total_rows = len(full_df)\n",
    "train_size = 0.8\n",
    "k = int(math.sqrt(total_rows * train_size))\n",
    "print(f\"k used: {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace53e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "knn = KNeighborsClassifier(n_neighbors=k) # using trial and error 77 seemed to be the best score but it's still bad\n",
    "knn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4761c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4c6409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Check if there's overfitting\n",
    "train_score = knn.score(X_train_scaled, y_train)\n",
    "test_score = knn.score(X_test_scaled, y_test)\n",
    "print(f\"Train accuracy: {train_score:.4f}\")\n",
    "print(f\"Test accuracy: {test_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
